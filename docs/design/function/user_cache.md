# 用户缓存功能设计

## 实现功能

1. **用户船只排行榜（单个服务器）**

   - 功能: 实现某个船只在某一个服务器下排行榜

   - 数据: 读取 `指定船只id` 和 `指定服务器id` 下所有用户数据，进行处理排序

2. **用户船只排行榜（所有服务器）**

   - 功能: 实现某个船只在全服下的排行榜

   - 数据: 读取 `指定船只id` 下所有用户数据，进行处理排序

3. **指定用户列表排行榜**

   - 功能: 实现在不同服务器的用户列表的排行榜（就是群排名）

   - 数据: 读取 `指定船只id` 下 `指定用户id列表` 数据，进行处理排序

4. **服务器数据统计**

   - 功能: 实现统计某个船只的所有用户数据，计算平均值、近期值等

   - 数据: 读取 `指定船只id` 下所有用户数据，累加计算

## 数据库设计思路

### 1. 用户缓存基本信息表

缓存用户的所有船只的基本数据和缓存上次更新时间，用于用户信息的更新，储存的具体是两个数据：

1. 用户上次缓存更新时间，用于更新时判断用户是否需要更新，是否需要更新由用户的活跃等级确定

2. 用户上次更新时数据的缓存，记录所有船只 id 和数据中的总场数，用于更新时判断是否需要更新数据库

### 2. 用户缓存具体数据表

数据单位是一个用户的一个船只的数据，记录用户船只的详细数据，用于计算排行榜等数据

```txt
| - 船只id - | - 服务器id - | - 用户id - | --- 具体数据等 --- | - 其他 - |

建立索引: 船只id+服务器id+用户id
```

## 数据库分表思路

根据当前数据规模和预期数据增长规模判断，如果只用一个数据表储存，数量将会超过 3kw 行数据，需要考虑如何分库或者分表

> 对于当前采用的 InnoDB 引擎，由于底层的 b+树在超过 2190w 行时，树高度会超过 3 层，降低效率

对于上面所提到的几个功能里面，索引均包括船只 id，所以数据库分表的最小单位是船只 id，如果更小会导致数据查询时的问题

对于这个问题，就可以根据船只 id 来分表，其中船只 id 又有船只等级、国家、类型等属性，所以有以下几个思路

### 1. 按照船只 id 分表

最简单的分表思路，给每一个船只 id 都新建一个表，只存储这个船只 id 的数据

但是会导致分出几百个表，不方便管理，其次，每次读取数据前还需要判断表是否存在，降低查询效率

### 2. 按照船只 id 的属性分表

根据船只的属性，例如类型或者等级，可以有效降低分出的数据表的数量

但是会导致分出的表内数据极不平衡，例如某个表内数据达到几千万行，但是某个表内只有几十万行，受船只属性影响很大

### 3. 按照船只 id 取余分表

根据船只 id 取余，分 2^n 个表，在实现分表的情况下受船只属性影响最小

但是如果后续有需要从多个船只 id 中读取数据时会有问题，而且并不能完全保证不受属性影响

## 数据库更新思路

首选，由于整体用户量很大，有几百万的规模，所以不要求每个用户都及时更新，根据用户的活跃等级来判断用户更新频率，同时支持用户手动更新

1. 每次从数据库中取出一定数量的用户，遍历这个范围内的用户，通过用户的活跃等级和最后更新时间，判断用户是否需要更新

2. 对于需要更新的用户，通过接口请求数据，获取用户所有船只数据的简略信息

3. 通过接口获取的数据，和缓存内的数据对比，如果某个船只 id 的数据不匹配则更新数据

4. 将需要更新的数据写对应的表中

## 具体功能实现原理

### 船只排行榜

根据需要，从数据库中读取指定船只 id 的用户数据。这次提取出来的是还未处理过的原始数据

获取数据后，首先排除不符合要求的数据，再将数据进行初步处理，获取用于计算 pr 的初步数据

将处理后的初步数据遍历计算 pr 值，按照 pr 进行排序，得到排行榜所需要的数据。此时数据已经足够，只需要获取用户 id 对应的名称即可

将上面计算好的数据存入缓存中，如果需要查看某个船只前 100 名的用户，则首先从缓存中读取这前 100 的用户的数据，在从数据库缓存中获取这些用户的名称返回

### 用户排行榜（群排名）

从相关接口获取群或者频道的所有用户，通过绑定数据获取这些用户的绑定游戏账号

首先检测用户数量，避免过大的用户数量导致数据读取问题。例如最多只支持 500 个用户

然后步骤和排行榜基本一致

### 服务器数据统计

按照船只 id，遍历所有数据，累计即可获取服务器平均数据

如果需要计算近期数据，则需要将这次的累加值和上次的累加值相减

不过需要考虑的是，如果在某个统计区间内，某个用户被写如数据库，则统计近期数据时会被全部统计进去

为了解决上述问题，可以通过用户的 created_time 来排除异常数据
